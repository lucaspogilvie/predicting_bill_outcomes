{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c6dbd3-7649-4753-8c5a-99f6b5d309af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, recall_score, balanced_accuracy_score, f1_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9fa06-7640-4236-8ad9-15cdd9de86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['title', 'gov_party','senate_party','house_party','state_party_control','party_of_1st_chamber','party_of_2nd_chamber']]\n",
    "y = df['law_enacted']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83106d1f-1064-4503-af9a-65abb5c538ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metrics(estimator, X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test):\n",
    "    \n",
    "    train_preds = estimator.predict(X_train)\n",
    "    preds = estimator.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "    train_recall = recall_score(y_train, train_preds)\n",
    "    test_acc = accuracy_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    balanced = balanced_accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc}')\n",
    "    print(f'Test Recall: {train_recall}')\n",
    "    print(f'Test Accuracy: {test_acc}')\n",
    "    print(f'Balanced Accuracy: {balanced}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print()\n",
    "    print(f'Test Confusion Matrix:')\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(estimator, X_test, y_test)\n",
    "    \n",
    "    return {\n",
    "        'balanced_accuracy': balanced,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d88c51-ce8b-45b1-8794-62b5edd2f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List that will keep track of metrics\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36577ad6-c916-4283-8053-fc684b0bff6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44207a3-5d8c-45e7-8a82-0e0a340be134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d38f75-b115-4530-b90e-5f764c3b2637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
